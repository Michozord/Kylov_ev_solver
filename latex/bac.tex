\documentclass[a4paper,11pt,bibliography=totoc,listof=totoc,headinclude=true,cleardoublepage=empty,oneside]{scrbook}
% Option "oneside" für einseitigen Druck. Weglassen, falls die Arbeit doppelseitig gedruckt wird

\usepackage[english,ngerman]{babel}
\usepackage[utf8]{inputenc}
%\usepackage{fullpage}
\usepackage{ifthen}
\usepackage{color}
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}

% links in pdf
\usepackage[unicode,colorlinks=true,pagebackref=false]{hyperref}

\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{rem}[theorem]{Remark}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\bigO}{\mathcal{O}}

% Zum Druck verwende schwarze Links!
%\usepackage[unicode,colorlinks=true,linkcolor=black,citecolor=black,urlcolor=black,pagebackref=false]{hyperref} 
	% colorlinks=false umrahmt Links statt einzufaerben, 


% document style
\KOMAoptions{footinclude=false} % Fusszeile wird nicht zu Satzspiegel gezaehlt
\KOMAoptions{headsepline=true} % Trennlinie zwischen Kopfzeile und Text
\KOMAoptions{DIV=12} % beeinflusst Satzspiegel
\KOMAoptions{BCOR=8mm} % Bindekorrektur
\pagestyle{headings} % mit Kopfzeilen

\recalctypearea % berechne Satzspiegel neu

\definecolor{change}{rgb}{0,.55,.55}

\def\revision#1{{\color{red}#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TITELSEITE [OBLIGATORISCH]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagenumbering{Alph}
\selectlanguage{ngerman}

\begin{titlepage}
  %\vspace*{-2cm}
  \begin{center}
    \includegraphics[width=0.45\textwidth]{TULogo.eps}
    \vskip 1cm%
    {\LARGE B~\Large A~C~H~E~L~O~R~A~R~B~E~I~T}
    \vskip 8mm
    {\huge\bfseries\color{change}Titel \\[1ex] ggf.\ mehrzeilig}
    \vskip 1cm
    \large 
    ausgef\"uhrt am    
    \vskip 0.75cm
    {\Large Institut f\"ur\\[1ex] Analysis und Scientific Computing}\\[1ex]
    {\Large TU Wien}
    \vskip0.75cm
    unter der Anleitung von
    \vskip0.75cm
    {\Large\bfseries 
Associate Prof. Dipl.-Math. Dr.rer.nat. Lothar Nannen}\\[1ex]
    \vskip 0.5cm
    durch
    \vskip 0.5cm
    {\Large\bfseries Michał Trojanowski}\\[1ex]
    Matrikelnummer: 12108865\\[1ex]
  \end{center}
  
  \vfill
  
  \small
  Wien, am \today
  \vspace*{-15mm}
\end{titlepage}

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DANKSAGUNG / ACKNOWLEDGEMENT [OPTIONAL]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Danksagung} %\chapter*{Acknowledgement}
\thispagestyle{empty}
\selectlanguage{ngerman} %\selectlanguage{english}

{\color{change}
\begin{itemize}
\item auf Deutsch oder Englisch
\item Die Danksagung (engl. {\em Acknowledgement}) ist optional und kann auch entfallen. Denken Sie ggf.\ an Ihre eigenen Eltern!

\item Falls die Arbeit durch eine Forschungsprojekt finanziert wurde, so ist jedenfalls der Fördergeber (z.B.\ FWF oder WWTF) mit Projektnummer und Projektname zu nennen.
\begin{itemize}
\item siehe z.B.\ Dissertation von Michele Ruggeri:
\item[] \href{https://publik.tuwien.ac.at/files/publik_252806.pdf}{\ttfamily https://publik.tuwien.ac.at/files/publik\_252806.pdf}
\end{itemize}

\end{itemize}
}

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EIDESSTATTLICHE ERKLAERUNG [OBLIGATORISCH]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Eidesstattliche Erkl\"arung}
\thispagestyle{empty}
\selectlanguage{ngerman}
\thispagestyle{empty}

\vspace*{2cm}

Ich erkl\"are an Eides statt, dass ich die vorliegende Bachelorarbeit selbstst\"andig und ohne fremde Hilfe verfasst, andere als die angegebenen Quellen und Hilfsmittel nicht benutzt bzw. die w\"ortlich oder sinngem\"a{\ss} entnommenen Stellen als solche kenntlich gemacht habe.

\vspace*{3cm}

\noindent
Wien, am \today
%
\hfill 
%
\begin{minipage}[t]{5cm}
\centering
\underline{\hspace*{5cm}}\\
\small{Michał Trojanowski}
\end{minipage}

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INHALTSVERZEICHNIS [OBLIGATORISCH]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagenumbering{roman}
%\selectlanguage{ngerman} %
\selectlanguage{english} 

\tableofcontents

\cleardoublepage
\pagenumbering{arabic} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EINLEITUNG / INTRODUCTION [OBLIGATORISCH]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
\label{chapter:introduction}


\chapter{A Krylov eigenvalue solver based on filtered time domain solutions}
\label{chapter:ftd}
In this chapter we present concept of Krylov eigenvalue solver in a simple setting -- computation of eigenvalues of the negative Laplace operator. We formulate the weak form of the problem and introduce discretization in space. Then we define Krylov spaces and project our problem onto this spaces with smaller dimension. ..... This chapter is based on \cite{nannen}.
\begin{definition}[Eigenvalue problem of the negative Laplace operator]\label{def:ev problem}
    Let $\Omega~\subset~\R^d$ for $d=2,3$ be a bounded domain with Lipschitz boundary. We solve for eigenvalues $\omega^2~\in~\R_{+}$ and eigenfunctions $u\in H^1(\Omega)$ of the negative Laplace operator with Neumann boundary conditions:
        \begin{align}\begin{split}\label{eq:ev problem}
              -\Delta u &= \omega^2 u \hspace{.3cm} \text{ in } \Omega, \\
              \frac{\partial u}{\partial \nu} &= 0 \hspace{.3cm}\text{ on } \partial\Omega.
        \end{split}\end{align}
    Here $\frac{\partial}{\partial\nu}$ denotes the normal derivative and $H^1$ is the Sobolev space. 
\end{definition}
Now we discretize the problem in space and we fix the partition $\mathcal{T}$ of $\Omega$. We introduce a discrete solution space as a finite-dimensional space of piecewise polynomials on $\Omega$. 
\begin{definition}[Discrete solution space]\label{def:solution space}
    Let $\mathcal{P}_p$ denote the space of polynomials up to degree $p \in \N$. We define discrete solution space as  
    \begin{equation*}
        V_h := \{v \in H^1(\Omega): \hspace{.3cm} \forall T \in \mathcal{T} \, v|_T \in \mathcal{P}_p \}
    \end{equation*}
    with finite dimension $N := \mathrm{dim} (V_h)$. 
\end{definition}

Using Gauss theorem, we can formulate the weak and discrete form of the problem \eqref{eq:ev problem}.
\begin{definition}[Weak formulation of eigenvalue problem]\label{def:weak form}
    Let $\Omega$ be a bounded Lipschitz domain, like in Definition \ref{def:ev problem}, and $V_h$ be the discrete solution space. We solve for eigenvalues $\omega_h^2 \in \R_+$ corresponding to discrete eigenfunctions $u \in V_h$, such that for all test functions $\varphi \in V_h$ holds:
    \begin{equation}\label{eq:weak form}
        \int_\Omega \nabla u \cdot \nabla \varphi \, dx = \omega_h^2 \int_\Omega u \varphi \, dx.
    \end{equation}  
\end{definition}
To simplify the notation in the subsequent part, we neglect the use of index $h$ for discrete eigenfunctions and eigenvalues. Now we show, that the discrete eigenvalue problem \eqref{eq:weak form} is in fact just an eigenvalue problem for a matrix, since our solutions space is finite-dimensional. 
\begin{definition}\label{def:SM matrices}
    Let $V_h$ be $N$-dimensional solution space with basis $(\varphi_1, \dots, \varphi_N)$. We define matrices $S:=(s_{ij})_{i, j=1}^N $ and $M:=(m_{ij})_{i, j=1}^N $ with:
    \begin{equation*}
        s_{ij} := \int_\Omega \nabla \varphi_i \cdot \nabla \varphi_j \, dx \hspace{.7cm} \text{ and } \hspace{.7cm} m_{ij} := \int_\Omega \varphi_i \varphi_j \, dx.
    \end{equation*}
\end{definition}
\begin{lemma}
    Equivalent to the problem Definition \ref{def:weak form} is eigenvalue problem to find non-trivial $v \in \R^N$ and $\omega^2 \in \R_+$, such that:
    \begin{equation}\label{eq:matrix form}
        Sv = \omega^2 Mv
    \end{equation}
    with matrices $S, M \in \R^{N \times N}$ from Definition \ref{def:SM matrices}.
\end{lemma}
\begin{proof}
    Since $(\varphi_1, \dots, \varphi_N)$ is a basis of $V_h$, it is sufficient, if \eqref{eq:weak form} holds for all basis functions. With sufficient $v\in \R^N$ we can also replace $u = (\varphi_1, \dots, \varphi_N) v$. We obtain:
    \begin{align*}
        \forall j=1, \dots, N : \, \int_\Omega (\nabla\varphi_1, \dots, \nabla\varphi_N)v\cdot \nabla \varphi_j \, dx &= \omega^2 \int_\Omega (\varphi_1, \dots, \varphi_N)v \varphi_j \, dx, \\
        \forall j=1, \dots, N : \, \int_\Omega (\nabla \varphi_j \cdot \nabla \varphi_1, \dots, \nabla \varphi_j \cdot \nabla \varphi_N) v \, dx &= \omega^2 \int_\Omega (\varphi_j\varphi_1, \dots, \varphi_j\varphi_N)v \,dx, \\ 
        \forall j = 1, \dots, N: \, (s_{j1},\dots,s_{jN})v &= \omega^2 (m_{j1},\dots, m_{jN})v,
    \end{align*}
    what is equivalent to \eqref{eq:matrix form}.
\end{proof}
\begin{rem}
    Matrices $S$ and $M$ from Definition \ref{def:SM matrices} are self-adjoint. Furthermore matrix $S$ is positive semi-definite and $M$ is positive-definite.
\end{rem}




\section{Elementary eigenvalue solvers for matrices}
Since we have reformulated eigenvalue problem of the negative Laplacian operator (see Definition \ref{def:ev problem}) into an eigenvalue problem for matrices, we recall elementary numerical algorithms to solve such problems. For proofs of convergence of those algorithms, we refer to \cite{numericsAB}. 

First algorithm provides approximation of an eigenvector to eigenvalue with largest absolute value among eigenvalues of a matrix. 

\begin{algorithm}[H]
\caption{Power iteration}\label{alg:power iteration}
\begin{algorithmic}
    \State \textbf{Input:} $A \in \R^{N \times N}$, start vector $v^{(0)}\in \R^N$
    \For{$i = 1, 2, \dots$}
        \State $v \gets Av^{(i-1)} $
        \State $v^{(i)} \gets \frac{v}{\|v\|_2}$
    \EndFor
    \State \textbf{Output:} $v^{(i)}$ -- approximation of an eigenvector to eigenvalue with largest absolute value.
    \end{algorithmic}
\end{algorithm}
\begin{theorem}
    Let $A \in \R^{N \times N}$ be a diagonalizable matrix with eigenvalues $\mu_1, \dots \mu_N$, such that $|\mu_1| > |\mu_2| \geq |\mu_j|$ for all $j  = 3,\dots,N$. Let $(v_1, \dots, v_N)$ denote a basis of $\R^N$, such that for all $j=1, \dots N$ $v_j$ is a normed eigenvector to eigenvalue $\mu_j$. Let $v = \sum_{j=1}^N c_j v_j \in \R^N$ be a start vector, such that $c_1 \neq 0$. Then for all $i \in \N$ holds error estimation for eigenspace:
    \begin{equation*}
        \left\| v^{(i)} - \frac{\mu_1^i c_1}{|\mu_1^i c_1|} v_1 \right\|_2 = \bigO\left( \left|\frac{\mu_2}{\mu_1}\right|^i\right) \text{ for } i \rightarrow \infty.
    \end{equation*}
    Furthermore holds error estimation for convergence of eigenvalue. Let $\mu^{(i)} := (Ax^{(i)})_k / x^{(i)}_k $ for some $k = 1, \dots, N$. It holds:
    \begin{equation*}
        |\mu_1 - \mu^{(i)}| = \bigO\left( \left|\frac{\mu_2}{\mu_1}\right|^i\right) \text{ for } i \rightarrow \infty.
    \end{equation*}
\end{theorem}
\begin{proof}
    We refer to \cite[p. 116]{numericsAB}.
\end{proof}

Second algorithm allows us to compute whole spectrum of a matrix. 
\begin{algorithm}[H]
\caption{QR algorithm}\label{alg:QR alg}
\begin{algorithmic}
    \State \textbf{Input:} $A \in \R^{N \times N}$
    \State $A^{(0)} \gets A$
    \For{$i = 1, 2, \dots$}
        \State compute QR-decomposition: $Q^{(i)} R^{(i)} = A^{(i-1)}$ 
        \State $A^{(i)} \gets R^{(i)}Q^{(i)}$
    \EndFor
    \State \textbf{Output:} $A^{(i)}$ -- approximation of upper triangular matrix with eigenvalues of $A$ on diagonal. 
    \end{algorithmic}
\end{algorithm}
\begin{theorem}
    Let $A \in \R^{N \times N}$ be a diagonalizable matrix with pairwise different absolute values of eigenvalues: $\mu_1 > \mu_2 > \dots > \mu_N$. Let $\Lambda^{(i)} := \left(A^{(i)}_{11}, \dots A^{(i)}_{NN}\right)$. Then $\Lambda^{(i)}$ converges linear towards $(\mu_1, \dots, \mu_N)$ for $i\rightarrow\infty$. 
\end{theorem}
\begin{proof}
    We refer to \cite[p. 120]{numericsAB}.
\end{proof}

Since our goal is to find eigenvalues of the negative Laplace operator, we could use the QR algorithm to obtain all eigenvalues of the discrete problem. However it is not possible due to high computation costs of QR algorithm. We focus on situations, where the problem on the discrete level is high-dimensional. QR algorithm demand computation of a QR-decomposition of a $N \times N$ matrix, what has cubic computational complexity. Therefore is this method for our problem out of reach. We have to deploy a method, that is based on direct solver, such as power iteration. 

\section{Krylov eigenvalue solver}
Now we need an assumption, that there exists matrix $C\in \R^{N \times N}$, such that its eigenvectors are exact eigenvectors of the discrete problem \eqref{eq:matrix form}. 
\begin{prop}\label{prop:C}
    Let $C \in \R^{N\times N}$ be a matrix, such that there exists eigenvalue $\mu \in \R$ to the eigenvector $w\in \R^N$, i.e., $Cw = \mu w$, if and only if $w$ is an eigenvector or linear combination of eigenvectors in the discrete problem \eqref{eq:matrix form} to some eigenvalue $\omega^2$.
\end{prop}
We obtain properties of the matrix $C$, that will be needed. Exact choice and construction of this matrix will be discussed later. We recall the definition of a Krylov space. 
\begin{definition}[Krylov space]
    Let $C \in \R^{N \times N}$ be a matrix and $r\in \R^N$ be a normalized start vector, i.e. $\|r\|=1$. For $m\in \N$ we define Krylov space as a subspace of $\R^N$:
    \begin{equation*}
        \mathcal{K}_m(C; r) := \mathrm{span}\left\{r, Cr, \dots, C^{m-1}r\right\}.
    \end{equation*}
\end{definition}
In this thesis we focus on situations, when $N$ is large. Our goal is to project $N$-dimensional eigenvalue problem \eqref{eq:matrix form} onto $m$-dimensional Krylov space, using orthonormal basis of this space. Typically we choose $m$ much smaller than $N$, so that this problem is solvable with low computational costs with direct solver. 
\begin{prop}
    Let $\mathcal{K}_m(C; r)$ be a $m$-dimensional Krylov space to matrix $C\in \R^{N\times N}$ and start vector $r\in \R^N$, $\|r\|=1$. We obtain an orthonormal basis $(b_0, \dots, b_{m-1})$ of Krylov space with Gram-Schmidt orthonormalization:
    \begin{equation*}
        b_0 := r, \text{ and } \widetilde{b}_{j} := Cb_{j-1} - \sum_{i=0}^{j-1} (b_i^T C b_{j-1}) b_i , \, b_j := \frac{\Tilde{b}_{j-1}}{\|\Tilde{b}_{j-1}\|_2} \text{ for all } j=1, \dots, m-1. 
    \end{equation*}
\end{prop}
Now we can project the original problem \eqref{eq:matrix form} onto $m$-dimensional Krylov space. 
\begin{prop}[Eigenvalue problem on Krylov space]
    Let $B_m = (b_0, \dots, b_{m-1}) \in \R^{N\times m}$ be an orthonormal basis of a $m$-dimensional Krylov space $\mathcal{K}_m(C; r)$. Eigenvalue problem on Krylov space is to find eigenvalues $\omega_m^2 \in \R_+$ and eigenvectors $v_m\in\R^m$, such that:
    \begin{equation}\label{eq:Krylov problem}
        B_m^T S B_m v_m = \omega_m^2 B_m^T M B_m v_m.
    \end{equation}
\end{prop}

Since matrices $S$ and $M$ are Hermitian, Krylov iteration leads to convergence of eigenspaces of \eqref{eq:Krylov problem} towards eigenspace of $C$ corresponding to eigenvalue $\mu_{max}$ with largest absolute value. Obviously, projected eigenvalues $\omega_m^2$ converge towards eigenvalue $\omega^2$ of original problem \eqref{eq:matrix form} to eigenspace corresponding to $\mu_{max}$.

%To sum up this section, we can explicit formulate an algorithm to compute eigenvalues in 

Our goal is to compute eigenvalues $\omega^2$ of \eqref{eq:matrix form} in a given region of interest $(\omega_{\min}^2, \omega_{\max}^2)$. Therefore we need, that matrix $C$ fulfills following four conditions.
\begin{itemize}
    \item $C$ satisfies conditions in Proposition \ref{prop:C}.
    \item Eigenvalues $\mu$ corresponding to eigenspaces of eigenvalues $\omega^2$ in region of interest have large absolute value.
    \item Eigenvalues $\mu$ corresponding to eigenspaces of eigenvalues $\omega^2$, that are unsought, should be close 0. 
    \item Each Krylov-step $r \mapsto Cr$ can be computed with low costs.
\end{itemize}
I other words, use of matrix $C$ filters sought eigenvalues from among all eigenvalues of the original problem \eqref{eq:matrix form} via common eigenspaces. 

\begin{rem}
    Shift-and-inverse matrix:
    \begin{equation*}
        C_\rho := (S - \rho M)^{-1}M
    \end{equation*}
    for some $\rho \in \R$ has eigenvalue $\mu = (\omega^2 - \rho)^{-1}$ corresponding to eigenspace to eigenvalue $\omega^2$ of original problem \eqref{eq:matrix form}. Therefore $C_\rho$ with $\rho = (\omega^2_{\min}+\omega^2_{\max})/2 $ would be a possible choice of matrix C. Nevertheless, it needs inverse of a $N\times N$ matrix $(S - \rho M)$, what for large $N$ is impossible with low computational complexity.
\end{rem}
\begin{proof}
    Let $(\mu, w)\in \R\times\R^N$ be an eigenpair of $C_\rho$:
    \begin{align*}
        C_\rho w &= \mu w,  \\
        (S - \rho M)^{-1}Mw &= \mu w, \\
        \frac{1}{\mu}Mw &= (S - \rho M)w, \\
        Sw &= \underbrace{\left(\rho - \frac{1}{\mu}\right)}_{\omega^2} Mw. 
    \end{align*}
    Therefore $\mu = (\omega^2 - \rho)^{-1}$. Obviously, $|\mu|$ takes on largest values, if $\omega^2 \approx \rho$.
\end{proof}

\section{Filtered time-domain solutions}







\chapter{Choice of the discrete filter function}
\label{chapter:dff}
\cite{nannen}\cite{numodes}

\bibliographystyle{alpha} 
%\bibliographystyle{abbrv}
\bibliography{literature.bib}

\end{document}
