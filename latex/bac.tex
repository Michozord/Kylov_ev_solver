\documentclass[a4paper,11pt,bibliography=totoc,listof=totoc,headinclude=true,cleardoublepage=empty,oneside]{scrbook}
% Option "oneside" für einseitigen Druck. Weglassen, falls die Arbeit doppelseitig gedruckt wird

\usepackage[english,ngerman]{babel}
\usepackage[utf8]{inputenc}
%\usepackage{fullpage}
\usepackage{ifthen}
\usepackage{color}
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}

% links in pdf
\usepackage[unicode,colorlinks=true,pagebackref=false]{hyperref}

\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{rem}[theorem]{Remark}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\renewcommand{\i}{\mathrm{i}}
\renewcommand{\Im}{\mathfrak{Im}}
\newcommand{\dff}{\Tilde{\beta}_\alpha}
\newcommand{\bigO}{\mathcal{O}}

\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}%


% Zum Druck verwende schwarze Links!
%\usepackage[unicode,colorlinks=true,linkcolor=black,citecolor=black,urlcolor=black,pagebackref=false]{hyperref} 
	% colorlinks=false umrahmt Links statt einzufaerben, 


% document style
\KOMAoptions{footinclude=false} % Fusszeile wird nicht zu Satzspiegel gezaehlt
\KOMAoptions{headsepline=true} % Trennlinie zwischen Kopfzeile und Text
\KOMAoptions{DIV=12} % beeinflusst Satzspiegel
\KOMAoptions{BCOR=8mm} % Bindekorrektur
\pagestyle{headings} % mit Kopfzeilen

\recalctypearea % berechne Satzspiegel neu

\definecolor{change}{rgb}{0,.55,.55}

\def\revision#1{{\color{red}#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TITELSEITE [OBLIGATORISCH]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagenumbering{Alph}
\selectlanguage{ngerman}

\begin{titlepage}
  %\vspace*{-2cm}
  \begin{center}
    \includegraphics[width=0.45\textwidth]{TULogo.eps}
    \vskip 1cm%
    {\LARGE B~\Large A~C~H~E~L~O~R~A~R~B~E~I~T}
    \vskip 8mm
    {\huge\bfseries\color{change}Titel \\[1ex] ggf.\ mehrzeilig}
    \vskip 1cm
    \large 
    ausgef\"uhrt am    
    \vskip 0.75cm
    {\Large Institut f\"ur\\[1ex] Analysis und Scientific Computing}\\[1ex]
    {\Large TU Wien}
    \vskip0.75cm
    unter der Anleitung von
    \vskip0.75cm
    {\Large\bfseries 
Associate Prof. Dipl.-Math. Dr.rer.nat. Lothar Nannen}\\[1ex]
    \vskip 0.5cm
    durch
    \vskip 0.5cm
    {\Large\bfseries Michał Trojanowski}\\[1ex]
    Matrikelnummer: 12108865\\[1ex]
  \end{center}
  
  \vfill
  
  \small
  Wien, am \today
  \vspace*{-15mm}
\end{titlepage}

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DANKSAGUNG / ACKNOWLEDGEMENT [OPTIONAL]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Danksagung} %\chapter*{Acknowledgement}
\thispagestyle{empty}
\selectlanguage{ngerman} %\selectlanguage{english}

{\color{change}
\begin{itemize}
\item auf Deutsch oder Englisch
\item Die Danksagung (engl. {\em Acknowledgement}) ist optional und kann auch entfallen. Denken Sie ggf.\ an Ihre eigenen Eltern!

\item Falls die Arbeit durch eine Forschungsprojekt finanziert wurde, so ist jedenfalls der Fördergeber (z.B.\ FWF oder WWTF) mit Projektnummer und Projektname zu nennen.
\begin{itemize}
\item siehe z.B.\ Dissertation von Michele Ruggeri:
\item[] \href{https://publik.tuwien.ac.at/files/publik_252806.pdf}{\ttfamily https://publik.tuwien.ac.at/files/publik\_252806.pdf}
\end{itemize}

\end{itemize}
}

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EIDESSTATTLICHE ERKLAERUNG [OBLIGATORISCH]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Eidesstattliche Erkl\"arung}
\thispagestyle{empty}
\selectlanguage{ngerman}
\thispagestyle{empty}

\vspace*{2cm}

Ich erkl\"are an Eides statt, dass ich die vorliegende Bachelorarbeit selbstst\"andig und ohne fremde Hilfe verfasst, andere als die angegebenen Quellen und Hilfsmittel nicht benutzt bzw. die w\"ortlich oder sinngem\"a{\ss} entnommenen Stellen als solche kenntlich gemacht habe.

\vspace*{3cm}

\noindent
Wien, am \today
%
\hfill 
%
\begin{minipage}[t]{5cm}
\centering
\underline{\hspace*{5cm}}\\
\small{Michał Trojanowski}
\end{minipage}

\cleardoublepage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INHALTSVERZEICHNIS [OBLIGATORISCH]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagenumbering{roman}
%\selectlanguage{ngerman} %
\selectlanguage{english} 

\tableofcontents

\cleardoublepage
\pagenumbering{arabic} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EINLEITUNG / INTRODUCTION [OBLIGATORISCH]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
\label{chapter:introduction}


\chapter{A Krylov eigenvalue solver based on filtered time domain solutions}
\label{chapter:ftd}
In this chapter we present concept of Krylov eigenvalue solver computing eigenvalues of the negative Laplace operator. We 

This chapter is based on \cite{nannen}.
\begin{definition}[Eigenvalue problem of the negative Laplace operator]\label{def:ev problem}
    Let $\Omega~\subset~\R^d$ for $d=2,3$ be a bounded domain with Lipschitz boundary. We solve for eigenvalues $\omega^2~\in~\R_{+}$ and eigenfunctions $u\in H^1(\Omega)$ of the negative Laplace operator with Neumann boundary conditions:
        \begin{align}\begin{split}\label{eq:ev problem}
              -\Delta u &= \omega^2 u \hspace{.3cm} \text{ in } \Omega, \\
              \frac{\partial u}{\partial \nu} &= 0 \hspace{.3cm}\text{ on } \partial\Omega.
        \end{split}\end{align}
    Here $\frac{\partial}{\partial\nu}$ denotes the normal derivative and $H^1$ is the Sobolev space. 
\end{definition}
Now we discretize the problem in space and we fix the partition $\mathcal{T}$ of $\Omega$. We introduce a discrete solution space as a finite-dimensional space of piecewise polynomials on $\Omega$. 
\begin{definition}[Discrete solution space]\label{def:solution space}
    Let $\mathcal{P}_p$ denote the space of polynomials up to degree $p \in \N$. We define discrete solution space as  
    \begin{equation*}
        V_h := \{v \in H^1(\Omega): \hspace{.3cm} \forall T \in \mathcal{T} \, v|_T \in \mathcal{P}_p \}
    \end{equation*}
    with finite dimension $N := \mathrm{dim} (V_h)$. 
\end{definition}

Using Gauss theorem, we can formulate the weak and discrete form of the problem \eqref{eq:ev problem}.
\begin{definition}[Weak formulation of eigenvalue problem]\label{def:weak form}
    Let $\Omega$ be a bounded Lipschitz domain, like in Definition \ref{def:ev problem}, and $V_h$ be the discrete solution space. We solve for eigenvalues $\omega_h^2 \in \R_+$ corresponding to discrete eigenfunctions $u \in V_h$, such that for all test functions $\varphi \in V_h$ holds:
    \begin{equation}\label{eq:weak form}
        \int_\Omega \nabla u \cdot \nabla \varphi \, dx = \omega_h^2 \int_\Omega u \varphi \, dx.
    \end{equation}  
\end{definition}
To simplify the notation in the subsequent part, we neglect the use of index $h$ for discrete eigenfunctions and eigenvalues. Now we show, that the discrete eigenvalue problem \eqref{eq:weak form} is in fact just an eigenvalue problem for a matrix, since our solutions space is finite-dimensional. 
\begin{definition}\label{def:SM matrices}
    Let $V_h$ be $N$-dimensional solution space with basis $(\varphi_1, \dots, \varphi_N)$. We define matrices $S:=(s_{ij})_{i, j=1}^N $ and $M:=(m_{ij})_{i, j=1}^N $ with:
    \begin{equation*}
        s_{ij} := \int_\Omega \nabla \varphi_i \cdot \nabla \varphi_j \, dx \hspace{.7cm} \text{ and } \hspace{.7cm} m_{ij} := \int_\Omega \varphi_i \varphi_j \, dx.
    \end{equation*}
\end{definition}
\begin{lemma}
    Equivalent to the problem Definition \ref{def:weak form} is eigenvalue problem to find non-trivial $v \in \R^N$ and $\omega^2 \in \R_+$, such that:
    \begin{equation}\label{eq:matrix form}
        Sv = \omega^2 Mv
    \end{equation}
    with matrices $S, M \in \R^{N \times N}$ from Definition \ref{def:SM matrices}.
\end{lemma}
\begin{proof}
    Since $(\varphi_1, \dots, \varphi_N)$ is a basis of $V_h$, it is sufficient, if \eqref{eq:weak form} holds for all basis functions. With sufficient $v\in \R^N$ we can also replace $u = (\varphi_1, \dots, \varphi_N) v$. We obtain:
    \begin{align*}
        \forall j=1, \dots, N : \, \int_\Omega (\nabla\varphi_1, \dots, \nabla\varphi_N)v\cdot \nabla \varphi_j \, dx &= \omega^2 \int_\Omega (\varphi_1, \dots, \varphi_N)v \varphi_j \, dx, \\
        \forall j=1, \dots, N : \, \int_\Omega (\nabla \varphi_j \cdot \nabla \varphi_1, \dots, \nabla \varphi_j \cdot \nabla \varphi_N) v \, dx &= \omega^2 \int_\Omega (\varphi_j\varphi_1, \dots, \varphi_j\varphi_N)v \,dx, \\ 
        \forall j = 1, \dots, N: \, (s_{j1},\dots,s_{jN})v &= \omega^2 (m_{j1},\dots, m_{jN})v,
    \end{align*}
    what is equivalent to \eqref{eq:matrix form}.
\end{proof}
\begin{rem}
    Matrices $S$ and $M$ from Definition \ref{def:SM matrices} are self-adjoint. Furthermore matrix $S$ is positive semi-definite and $M$ is positive-definite.
\end{rem}




\section{Elementary eigenvalue solvers for matrices}
Since we have reformulated eigenvalue problem of the negative Laplacian operator (see Definition \ref{def:ev problem}) into an eigenvalue problem for matrices, we recall elementary numerical algorithms to solve such problems. For proofs of convergence of those algorithms, we refer to \cite{numericsAB}. 

First algorithm provides approximation of an eigenvector to eigenvalue with largest absolute value among eigenvalues of a matrix. 

\begin{algorithm}[H]
\caption{Power iteration}\label{alg:power iteration}
\begin{algorithmic}
    \State \textbf{Input:} $A \in \R^{N \times N}$, start vector $v^{(0)}\in \R^N$
    \For{$i = 1, 2, \dots$}
        \State $v \gets Av^{(i-1)} $
        \State $v^{(i)} \gets \frac{v}{\|v\|_2}$
    \EndFor
    \State \textbf{Output:} $v^{(i)}$ -- approximation of an eigenvector to eigenvalue with largest absolute value.
    \end{algorithmic}
\end{algorithm}
\begin{theorem}
    Let $A \in \R^{N \times N}$ be a diagonalizable matrix with eigenvalues $\mu_1, \dots \mu_N$, such that $|\mu_1| > |\mu_2| \geq |\mu_j|$ for all $j  = 3,\dots,N$. Let $(v_1, \dots, v_N)$ denote a basis of $\R^N$, such that for all $j=1, \dots N$ $v_j$ is a normed eigenvector to eigenvalue $\mu_j$. Let $v = \sum_{j=1}^N c_j v_j \in \R^N$ be a start vector, such that $c_1 \neq 0$. Then for all $i \in \N$ holds error estimation for eigenspace:
    \begin{equation*}
        \left\| v^{(i)} - \frac{\mu_1^i c_1}{|\mu_1^i c_1|} v_1 \right\|_2 = \bigO\left( \left|\frac{\mu_2}{\mu_1}\right|^i\right) \text{ for } i \rightarrow \infty.
    \end{equation*}
    Furthermore holds error estimation for convergence of eigenvalue. Let $\mu^{(i)} := (Ax^{(i)})_k / x^{(i)}_k $ for some $k = 1, \dots, N$. It holds:
    \begin{equation*}
        |\mu_1 - \mu^{(i)}| = \bigO\left( \left|\frac{\mu_2}{\mu_1}\right|^i\right) \text{ for } i \rightarrow \infty.
    \end{equation*}
\end{theorem}
\begin{proof}
    We refer to \cite[p. 116]{numericsAB}.
\end{proof}

Second algorithm allows us to compute whole spectrum of a matrix. 
\begin{algorithm}[H]
\caption{QR algorithm}\label{alg:QR alg}
\begin{algorithmic}
    \State \textbf{Input:} $A \in \R^{N \times N}$
    \State $A^{(0)} \gets A$
    \For{$i = 1, 2, \dots$}
        \State compute QR-decomposition: $Q^{(i)} R^{(i)} = A^{(i-1)}$ 
        \State $A^{(i)} \gets R^{(i)}Q^{(i)}$
    \EndFor
    \State \textbf{Output:} $A^{(i)}$ -- approximation of upper triangular matrix with eigenvalues of $A$ on diagonal. 
    \end{algorithmic}
\end{algorithm}
\begin{theorem}
    Let $A \in \R^{N \times N}$ be a diagonalizable matrix with pairwise different absolute values of eigenvalues: $\mu_1 > \mu_2 > \dots > \mu_N$. Let $\Lambda^{(i)} := \left(A^{(i)}_{11}, \dots A^{(i)}_{NN}\right)$. Then $\Lambda^{(i)}$ converges linear towards $(\mu_1, \dots, \mu_N)$ for $i\rightarrow\infty$. 
\end{theorem}
\begin{proof}
    We refer to \cite[p. 120]{numericsAB}.
\end{proof}

Since our goal is to find eigenvalues of the negative Laplace operator, we could use the QR algorithm to obtain all eigenvalues of the discrete problem. However it is not possible due to high computation costs of QR algorithm. We focus on situations, where the problem on the discrete level is high-dimensional. QR algorithm demand computation of a QR-decomposition of a $N \times N$ matrix, what has cubic computational complexity. Therefore is this method for our problem out of reach. We have to deploy a method, that is based on direct solver, such as power iteration. 

\section{Krylov eigenvalue solver}
Now we need an assumption, that there exists matrix $C\in \R^{N \times N}$, such that its eigenvectors are exact eigenvectors of the discrete problem \eqref{eq:matrix form}. 
\begin{prop}\label{prop:C}
    Let $C \in \R^{N\times N}$ be a matrix, such that there exists eigenvalue $\mu \in \R$ to the eigenvector $w\in \R^N$, i.e., $Cw = \mu w$, if and only if $w$ is an eigenvector or linear combination of eigenvectors in the discrete problem \eqref{eq:matrix form} to some eigenvalue $\omega^2$.
\end{prop}
We obtain properties of the matrix $C$, that will be needed. Exact choice and construction of this matrix will be discussed later. We recall the definition of a Krylov space. 
\begin{definition}[Krylov space]
    Let $C \in \R^{N \times N}$ be a matrix and $r\in \R^N$ be a normalized start vector, i.e. $\|r\|=1$. For $m\in \N$ we define Krylov space as a subspace of $\R^N$:
    \begin{equation*}
        \mathcal{K}_m(C; r) := \mathrm{span}\left\{r, Cr, \dots, C^{m-1}r\right\}.
    \end{equation*}
\end{definition}
In this thesis we focus on situations, when $N$ is large. Our goal is to project $N$-dimensional eigenvalue problem \eqref{eq:matrix form} onto $m$-dimensional Krylov space, using orthonormal basis of this space. Typically we choose $m$ much smaller than $N$, so that this problem is solvable with low computational costs with direct solver. 
\begin{prop}
    Let $\mathcal{K}_m(C; r)$ be a $m$-dimensional Krylov space to matrix $C\in \R^{N\times N}$ and start vector $r\in \R^N$, $\|r\|=1$. We obtain an orthonormal basis $(b_0, \dots, b_{m-1})$ of Krylov space with Gram-Schmidt orthonormalization:
    \begin{equation*}
        b_0 := r, \text{ and } \widetilde{b}_{j} := Cb_{j-1} - \sum_{i=0}^{j-1} (b_i^T C b_{j-1}) b_i , \, b_j := \frac{\Tilde{b}_{j-1}}{\|\Tilde{b}_{j-1}\|_2} \text{ for all } j=1, \dots, m-1. 
    \end{equation*}
\end{prop}
Now we can project the original problem \eqref{eq:matrix form} onto $m$-dimensional Krylov space. 
\begin{prop}[Eigenvalue problem on Krylov space]
    Let $B_m = (b_0, \dots, b_{m-1}) \in \R^{N\times m}$ be an orthonormal basis of a $m$-dimensional Krylov space $\mathcal{K}_m(C; r)$. Eigenvalue problem on Krylov space is to find eigenvalues $\omega_m^2 \in \R_+$ and eigenvectors $v_m\in\R^m$, such that:
    \begin{equation}\label{eq:Krylov problem}
        B_m^T S B_m v_m = \omega_m^2 B_m^T M B_m v_m.
    \end{equation}
\end{prop}

Since matrices $S$ and $M$ are Hermitian, Krylov iteration leads to convergence of eigenspaces of \eqref{eq:Krylov problem} towards eigenspace of $C$ corresponding to eigenvalue $\mu_{max}$ with largest absolute value. Obviously, projected eigenvalues $\omega_m^2$ converge towards eigenvalue $\omega^2$ of original problem \eqref{eq:matrix form} to eigenspace corresponding to $\mu_{max}$.

To sum up core idea of this section, we can explicit formulate an (not implementable yet) algorithm based on Krylov spaces to compute eigenvalues $\omega^2$.
\begin{algorithm}[H]
\caption{Krylov eigenvalue solver}\label{alg:Krylov base}
    \begin{algorithmic}
        \State \textbf{Input:} matrix $C$, start vector $r$, $M^{-1}$, $S$, $m$ dimension of the Krylov space
        \State $b_0 \gets r$
        \For{$ k = 1, \dots, m-1$}
            \State $b_k \gets Cb_{k-1}$ \Comment{Krylov step}
            \State $b_{k} \gets b_k - \sum_{i=0}^{k-1} (b_i^T b_k) b_i$ \Comment{Gram-Schmidt orthogonalisation}
            \State $ b_k \gets b_{k}/\|b_{k}\|_2 $\Comment{normalization}
        \EndFor
        \State $B_m \gets (b_0, \dots, b_{m-1})$ \Comment{Projection matrix}
        \State $A \gets B_m^T M^{-1}S B_m$
        \State solve $Av = \omega_m^2 v$ with power iteration

    \end{algorithmic}
\end{algorithm}


Our goal is to compute eigenvalues $\omega^2$ of \eqref{eq:matrix form} in a given region of interest $(\omega_{\min}^2, \omega_{\max}^2)$. Therefore we need, that matrix $C$ fulfills following four conditions.
\begin{itemize}
    \item $C$ satisfies conditions in Proposition \ref{prop:C}.
    \item Eigenvalues $\mu$ corresponding to eigenspaces of eigenvalues $\omega^2$ in region of interest have large absolute value.
    \item Eigenvalues $\mu$ corresponding to eigenspaces of eigenvalues $\omega^2$, that are unsought, should be close 0. 
    \item Each Krylov-step $r \mapsto Cr$ can be computed with low costs.
\end{itemize}
In other words, use of matrix $C$ filters sought eigenvalues from among all eigenvalues of the original problem \eqref{eq:matrix form} via common eigenspaces. 

\begin{rem}
    Shift-and-inverse matrix:
    \begin{equation*}
        C_\rho := (S - \rho M)^{-1}M
    \end{equation*}
    for some $\rho \in \R$ has eigenvalue $\mu = (\omega^2 - \rho)^{-1}$ corresponding to eigenspace to eigenvalue $\omega^2$ of original problem \eqref{eq:matrix form}. Therefore $C_\rho$ with $\rho = (\omega^2_{\min}+\omega^2_{\max})/2 $ would be a possible choice of matrix C. Nevertheless, it requires inverse of a $N\times N$ matrix $(S - \rho M)$, what for large $N$ is impossible with low computational complexity.
\end{rem}
\begin{proof}
    Let $(\mu, w)\in \R\times\R^N$ be an eigenpair of $C_\rho$:
    \begin{align*}
        C_\rho w &= \mu w,  \\
        (S - \rho M)^{-1}Mw &= \mu w, \\
        \frac{1}{\mu}Mw &= (S - \rho M)w, \\
        Sw &= \underbrace{\left(\rho - \frac{1}{\mu}\right)}_{\omega^2} Mw. 
    \end{align*}
    Therefore $\mu = (\omega^2 - \rho)^{-1}$. Obviously, $|\mu|$ takes on largest values, if $\omega^2 \approx \rho$.
\end{proof}

\section{Filtered time-domain solutions}
To construct appropriate finite-dimensional operator, that will replace role of the matrix $C$ from previous section, we proceed as follows. We consider homogeneous wave equation with some initial condition $u_0 = (\varphi_1, \dots, \varphi_N)r$ projected onto our discrete solution space $V_h$ (see Definition \ref{def:solution space}). We discretize the problem in space and formulate its weak form. The evaluation of our operator at the point $r$ is a time integral of the solution to this semi-discrete problem.

We consider homogeneous 2- or 3-dimensional wave equation in $\Omega \times (0, \infty)$:
\begin{align}
\begin{split}\label{eq:wave equation}
    \ddot{u} = \Delta u \, \,\, \text{in } \Omega \times (0, \infty),& \, \,\,  u = 0 \, \,\, \text{in } \partial\Omega\times (0, \infty),\\
    \,\,\,u( \cdot, 0)= u_0, & \, \dot{u}(\cdot, 0) = 0 \, \,\, \text{in } \Omega,
\end{split}
\end{align}
where $u$ is a function $\Omega \times [0, \infty) \rightarrow \R$ and $\ddot{u}$ denotes the second time-derivative.
\begin{prop}
    Let $V_h$ be a discrete solution space with basis $(\varphi_1, \dots, \varphi_N)$ and let $r$ denote the coordinate vector of the projection of $u_0$ onto $V_h$, i.e. $u_0 = (\varphi_1, \dots, \varphi_N)r$. Let $S$ and $M$ denote the matrices from Definition \ref{def:SM matrices}. Discretization in space of the problem \eqref{eq:wave equation} leads to following linear system of ordinary differential equations:
    \begin{align}\label{eq:discr wave equation}
    \begin{split}
        M \ddot{y}(t; r) &= -S y (t; r) \,\,\, \text{ for all } t \in (0, \infty) \\
        y(0; r) &= r, \, \dot{y}(0; r) = 0. 
    \end{split}
    \end{align}
\end{prop}
\begin{proof}
    Theory of partial differential equations leads us to ansatz $u(t, x) = \sum_{i=1}^\infty \kappa_i(t) \xi_i(x)$, where $\xi_i$ are the eigenfunctions of the negative Laplace operator \cite[p. 122]{Jungel}. Since we want to solve the problem in our solution space $V_h$, we can assume, that $u(\cdot, t)=(\varphi_1, \dots, \varphi_N)y(t)$ for some vector-valued function $y: [0, \infty) \rightarrow \R^N$.

    We reformulate $\ddot{u} = \Delta u$ to its weak form:
    \begin{align*}
        \forall \varphi \in V_h : \, \int_\Omega \ddot{u} \varphi \, dx &= \int_\Omega \Delta u \varphi \, dx, \\
        \forall \varphi \in V_h : \, \int_\Omega \ddot{u} \varphi \, dx &= - \int_\Omega \nabla  u\cdot  \nabla \varphi \, dx.
    \end{align*}
    $V_h$ is a finite-dimensional space, therefore condition "for all test functions" is equivalent to condition "for all basis test functions":
    \begin{align*}
        \forall j=1, \dots, N:\, \int_\Omega (\varphi_1, \dots, \varphi_N)\ddot{y} \varphi_j \, dx &= -  \int_\Omega (\nabla \varphi_1, \dots, \nabla \varphi_N)y\cdot  \nabla \varphi_j \, dx, \\
        M\ddot{y} &= -Sy.
    \end{align*}
    Remains to show the equivalence of initial conditions. For $u_0$ holds:
    \begin{equation*}
        (\varphi_1, \dots, \varphi_N)r = u_0 = u(\cdot, 0) = (\varphi_1, \dots, \varphi_N)y(0),
    \end{equation*}
    so $y(0) = r$ in $\Omega$ and similarly $\dot{y}(0) = 0$ in $\Omega$.
\end{proof}
Now we can solve semi-discrete wave equation \eqref{eq:discr wave equation} to construct an integral operator. 
\begin{lemma}\label{lemma:y solution}
    The unique solution to \eqref{eq:discr wave equation} is:
    \begin{equation}\label{eq:solution wave eq}
        y(t; r) = \sum_{j=1}^N \cos(\omega_j t) (v_j^T r) v_j,
    \end{equation}
    where $(v_j)_{j=1}^N$ is an orthonormal basis of $\R^N$ of eigenvectors of matrix $M^{-1}S$ with corresponding eigenvalues $\omega_j^2$.
\end{lemma}
\begin{proof}
    Because of symmetry of matrices $S$ and $M$, there exists an orthonormal basis $(v_j)_{j=1}^N$ of eigenvectors of $M^{-1}S$. We denote corresponding eigenvalues with $\omega_j^2$, $j=1, \dots N$. Obviously, for all $j=1, \dots, N$ and for all $c_{1j}, c_{2j}\in \R$ function $t\mapsto \left(c_{1j} \cos(\omega_j t) + c_{2j} \sin(\omega_j t)\right)v_j$ solves the differential equation \eqref{eq:discr wave equation}. Due to linearity of the problem, 
    \begin{equation*}
        y(t) = \sum_{j=1}^N \left(c_{1j} \cos(\omega_j t) + c_{2j} \sin(\omega_j t)\right)v_j
    \end{equation*}
    solves the differential equation. Initial values lead to the form \eqref{eq:solution wave eq}. Uniqueness of the solution follows from the Picard-Lindelöf theorem.
\end{proof}

Now we can define an integral operator, that maps initial value of the semi-discrete wave equation \eqref{eq:discr wave equation} to a weighted time-integral of its unique solution. Discrete form of this operator will take over the role of matrix $C$. Depending on choice of the weight function, eigenvalues of this discrete operator may fulfill requirements, that we have set for matrix $C$ in previous section. This will be discussed later in Chapter \ref{chapter:function}. 

\begin{definition}\label{def:pi_alpha}
    Let $\alpha: [0; \infty) \rightarrow \R$ be a piecewise continuous function with compact support. We define $\Pi_\alpha: \R^N \rightarrow \R^N$ as linear operator:
    \begin{equation*}
        \Pi_\alpha r := \int_0^\infty \alpha(t) y(t;r) \,dt,
    \end{equation*}
    where $y(t;r)$ is the unique solution to \eqref{eq:discr wave equation} from Lemma \ref{lemma:y solution}.
\end{definition}

Following lemma determines correspondence between eigenvalues of $\Pi_\alpha$ and eigenvalues of the original problem \eqref{eq:matrix form}.
\begin{lemma}
    Let $\beta_\alpha : [0, \infty) \rightarrow \R$ be filter function defined by:
    \begin{equation}\label{eq:cont filter function}
        \beta_\alpha(\omega) := \int_0^\infty \alpha(t) \cos(\omega t) \,dt. 
    \end{equation}
    Then hold following two statements.
    \begin{enumerate}
        \item If $\omega^2$ is an eigenvalue of \eqref{eq:discr wave equation} to eigenvector $v$, then $v$ is also an eigenvector of $\Pi_\alpha$ corresponding to eigenvalue $\beta_\alpha(\omega)$. 
        \item If $\lambda$ is an eigenvalue of $\Pi_\alpha$ corresponding to eigenvector $v$, then there exists eigenvalue $\omega^2$ of \eqref{eq:discr wave equation}, such that $\beta_\alpha (\omega) = \lambda$ and 
        \begin{equation*}
            v \in \bigoplus\{ U : \exists \omega \, U \text{ is eigenspace to eigenvalue to } \omega \text{ and } \beta_\alpha(\omega) = \lambda\}.
        \end{equation*}
    \end{enumerate}
\end{lemma}
\begin{proof}
    \begin{enumerate}
        \item If $v$ is an eigenvector of \eqref{eq:matrix form}, then it is equal $v_j$ from \eqref{eq:solution wave eq} for some $j=1, \dots, N$. Therefore $y(t, v) = \cos(\omega_j t)v$ and 
        \begin{equation*}
            \Pi_\alpha v = \int_0^\infty \alpha(t) \cos(\omega_j t) v \, dt = \beta_\alpha(\omega) v.
        \end{equation*}
        So the first claim holds.
        \item If $\lambda$ is an eigenvalue of $\Pi_\alpha$ to eigenvector $v$, then for all $k=1, \dots, N$ holds:
        \begin{align*}
             0 &= (\Pi_\alpha v - \lambda v)v_k = \int_0^\infty \alpha(t) \sum_{j=1}^N \cos(\omega_k t) (v_j^T v)\underbrace{(v_j^T v_k)}_{=\delta_{jk}} \, dt - \lambda v^Tv_k \\ &= \left(\int_0^\infty \alpha(t) \cos(\omega_kt) - \lambda \right)v_k^T v = (\beta_\alpha(\omega_k) - \lambda)v_k^T v.
        \end{align*}
        If $\beta_\alpha (\omega_k)\neq \lambda$, then $v_k^Tv = 0$, because $(v_k)_{k=1}^N$ is a basis. Therefore $v$ is in sum of eigenspaces to eigenvalues such that $\beta_\alpha(\omega_k) = \lambda)$. Moreover $v$ is an eigenvector, so $v\neq 0$. Therefore there exists at least one $k$, such that $v_k^T v \neq 0$, what implies $\beta_\alpha (\omega_k) = \lambda$. 
    \end{enumerate}
\end{proof}

\section{Discretization in time}
In previous section we constructed an operator $\Pi_\alpha$, that can fulfill our eigenvalue requirements and replace matrix $C$ in Krylov iteration. Exact computation of the value $\Pi_\alpha r$ is impossible for two reasons: it demands analytical solution $y(\cdot; r)$ to semi-discrete wave equation \eqref{eq:discr wave equation} and computation of an improper integral. 

In numerical method we replace integral in the definition of $\Pi_\alpha$ by rectangular rule. Since we need the values of function $y(\cdot; r)$ in quadrature nodes only, we can discretize the problem \eqref{eq:discr wave equation} in time and compute approximation of the exact solution in those points using finite difference method. 
\begin{lemma}[Finite difference method]\label{lemma:finite diffs}
    For given function $y \in C^4 ([a, b])$ and uniform mesh $(t_l := a+\tau l)_{l=0}^{L}$ with $L+1\in\N$ nodes and mesh-size $\tau = (a-b)/L$ there holds for all $l=1, \dots, L-1$:
    \begin{equation*}
        \ddot{y}(t_l) = \frac{y(t_{l+1}) - 2 y(t_l) + y(t_{l-1})}{\tau^2} + \bigO(\tau^2).
    \end{equation*}
\end{lemma}
\begin{proof}
    Straight-forward calculation, that follows from Taylor expansion of function $y$. We refer to \cite[p. 93]{numodes}.
\end{proof}

\begin{prop}[Finite difference method for semi-discrete wave equation]
    Let $\tau>0$ be step-size of a uniform mesh on $[0, \infty)$. Replacing the second time-derivatives in \eqref{eq:discr wave equation} by the finite differences from Lemma \ref{lemma:finite diffs} we obtain following approximation $y_l(r)$ of $y(l\tau; r)$ for all $l \in \N$:
    \begin{align}\label{eq:fd for wave eq}
    \begin{split}
        y_{l+1}(r) &:= -\tau^2M^{-1}S y_l(r) + 2y_l(r) - y_{l-1}(r) \, \text{ for } l \in \N, \\
        y_{-1}(r) &:= y_0(r) := r.
    \end{split}
    \end{align}
\end{prop}
\begin{proof}
    For initial values there holds $y(0; r) = r = y_0(r)$ and by Taylor expansion:
    \begin{equation*}
        y(-\tau, r) = y(0; r) - \tau \underbrace{\dot{y}(0; r)}_{=0} + \bigO(\tau^2) = r + \bigO(\tau^2) = y_{-1}(r) + \bigO(\tau^2).
    \end{equation*} 
    Replacing second time-derivative in \eqref{eq:discr wave equation} leads by finite difference leads to:
    \begin{align*}
        y((l+1)\tau; r) &- 2 y(l\tau; r) + y((l-1)\tau; r) = -\tau^2 M^{-1}S y(l\tau; r) + \bigO(\tau^4), \\
        y((l+1)\tau; r) &= -\tau^2 M^{-1}S y(l\tau; r) + 2y(l\tau; r) - y((l-1)\tau; r) + \bigO(\tau^4).
    \end{align*}
    Hence $y_l(r)$ defined in \eqref{eq:fd for wave eq} approximates $y(l\tau; r)$ for all $l \in \N$.
\end{proof}

\begin{prop}[Discrete operator for Krylov iteration]\label{prop:C operator}
    Let $L \in \N$ be the number of quadrature nodes and $T>0$ be the upper bound of integration. Discretization of the operator $\Pi_\alpha$ (see Definition \ref{def:pi_alpha}) by the rectangular rule with step-size $\tau = T/L$ and approximation $y(l\tau; r) \approx y_l(r)$ leads to discrete operator $C : \R^N \rightarrow \R^N$:
    \begin{equation}\label{eq:C operator}
        r \mapsto Cr := \sum_{l=0}^{L-1} \tau \alpha(l\tau) y_l(r).
    \end{equation}
\end{prop}

Discrete operator $C$ defined in Proposition \ref{prop:C operator} lets us avoid high computational costs in each Krylov step $r \mapsto Cr$. However, we have to verify coincidence between eigenpairs of $C$ and eigenpairs of the original problem \eqref{eq:matrix form}. For this reason we construct discrete filter function as discrete analogon of \eqref{eq:cont filter function}. 

If $r$ is an eigenvector of matrix $M^{-1}S$ to eigenvalue $\omega^2$, then time-stepping \eqref{eq:fd for wave eq} takes following form for all $n\in \N$:
\begin{equation}\label{eq:y_l q_l}
    y_l(r) = q_l(\omega)r  
\end{equation}
with $q_l(\omega)$ solution to following recursion:
\begin{align}\label{eq:q def}
    \begin{split}
        q_{l+1}(\omega) &:= (2-\tau^2\omega^2) q_l(\omega) - q_{l-1}(\omega) \, \text{ for } l \in \N,\\
        q_{-1}(\omega) &:= q_0(\omega) := 1.
    \end{split}
\end{align}
This linear difference problem has unique solution, that will be needed later in Lemma \ref{lemma:dff}. Therefore we analyse behaviour of the solution as $l$ tends to infinity.

\begin{lemma}[Courant--Friedrichs--Lewy condition for $q_l$]\label{lemma:cfl}
    For given $\tau > 0$ and $\omega > 0$, the unique solution to \eqref{eq:q def} is:
    \begin{equation*}
        q_l(\omega) = \frac{1 - \overline{c(\omega)}}{2\i \Im(c(\omega))} c(\omega)^l + \frac{c(\omega)-1}{2\i \Im(c(\omega))} \overline{c(\omega)}^l,
    \end{equation*}
    where 
    \begin{equation*}
        c(\omega) := 1 - \frac{\tau^2 \omega^2}{2} + \i \sqrt{1 - \left(1 - \frac{\tau^2 \omega^2}{2}\right)^2}.
    \end{equation*}
    Therefore if $\tau < 2/\omega$, then CFL condition is satisfied and $|c(\omega)|=1$, what implies boundness of $|q_l(\omega)|$ as $l \rightarrow \infty$. Otherwise $|q_l(\omega)|$ is unbounded.
\end{lemma}
\begin{proof}
    We refer to \cite[p. 6]{nannen}.
\end{proof}
\begin{lemma}\label{lemma:dff}
    Let $L\in \N$ be the number of quadrature nodes, $T$ be the upper bound of integral and $\tau = T/L$, like in Proposition \ref{prop:C operator}. Let $q_l(\omega)$ be defined for all $l \in N$ and $\omega \in \R$ by \eqref{eq:q def}. We define the discrete filter function $\dff: [0, \infty) \rightarrow \R$ by:
    \begin{equation*}
        \dff(\omega) := \sum_{l=0}^{L-1} \tau \alpha(\tau l) q_l(\omega).
    \end{equation*}
    \begin{enumerate}
        \item $\dff$ is a polynomial of degree $L-1$ in $\omega^2$.
        \item For $C$ defined in Proposition \ref{prop:C operator} holds $C = \dff(M^{-1}S)$.
        \item If $(\omega^2, v)$ is an eigenpair of original problem \eqref{eq:matrix form}, then $(\dff(\omega), v)$ is an eigenpair of $C$.
        \item If $(\lambda, v)$ is an eigenpair of $C$, then there exists $\omega \in \R$, such that $\omega^2$ is an eigenvalue of \eqref{eq:matrix form}, $\dff(\omega)=\lambda$ and
        \begin{equation*}
            v \in \bigoplus\{ U : \exists \omega \, U \text{ is eigenspace to eigenvalue to } \omega \text{ and } \dff(\omega) = \lambda\}.
        \end{equation*}
    \end{enumerate}
\end{lemma}
\begin{proof}
    First claim follows directly from construction of $q_l(\omega)$ \eqref{eq:q def}. Let $V: = (v_1, \dots, v_N)$ be an orthonormal basis of eigenvectors corresponding to eigenvalues $\omega_1^2, \dots, \omega_N^2$ of $M^{-1}S$. The spectral decomposition of $M^{-1}S$ is $M^{-1}S = V \mathrm{diag}(\omega_1^2, \dots, \omega_N^2) V^T$. Since \eqref{eq:fd for wave eq} is a linear difference equation, for arbitrary $r\in\R^N$ and for all $l\in \N$ we obtain:
    \begin{equation*}
        y_l(r) = y_l \left( \sum_{j=1}^N (r^T v_j)v_j \right) = \sum_{j=1}^N (r^T v_j)y_l(v_j) \stackrel{\eqref{eq:y_l q_l}}{=} \sum_{j=1}^N (r^T v_j)q_l(\omega_j)v_j.
    \end{equation*}
    Therefore holds by the definition of $C$:
    \begin{align*}
        Cr &= \sum_{l=0}^{L-1} \tau\alpha(l\tau) y_l(r) = \sum_{j=1}^N \sum_{l=1}^{L-1} \tau\alpha(l\tau)q_l(\omega_j) (r^T v_j) v_j \\ &= \sum_{j=1}^{N}\dff(\omega_j)(r^Tv_j)v_j = V \mathrm{diag}\left(\dff(\omega_1), \dots, \dff(\omega_N)\right)V^Tr = \dff(M^{-1} S)r.
    \end{align*}
    So the second statement holds. Third and fourth claims follow from the second one. Let $\dff(\omega) = \sum_{l=0}^{L-1} c_l \omega^{2l}$ for some $c_0, \dots, c_{L-1}\in \R$. If $v$ is an eigenvector of \eqref{eq:matrix form} to eigenvalue $\omega^2$, then:
    \begin{equation*}
        Cv = \dff(M^{-1}S)v = \sum_{l=0}^{L-1} c_l (M^{-1}S)^{2l}v = \sum_{l=0}^{L-1} c_l \omega^{2l}v = \dff(\omega)v,
    \end{equation*}
    so $\dff(\omega)$ is eigenvalue of $C$ to $v$. If $(\lambda, v)$ is an eigenpair of $C$, then for all $k=0,\dots, N$ holds:
    \begin{align*}
        0 &= (Cv - \lambda v)v_k = \left(\left(\dff(M^{-1}S)v_k\right)^Tv - \lambda v^T v_k\right) \\&= \dff(\omega_k)v_k^T v - \lambda v^T v_k = \left(\dff(\omega_k) - \lambda\right)v^T v_k.
    \end{align*}
    Since $v^Tv_k \neq 0$ for some $k=1, \dots, N$, holds $\lambda = \dff(\omega_k)$ and $v$ belongs to sum of all eigenspaces to eigenvalues $\omega^2$, such that $\dff(\omega) = \lambda$.
\end{proof}

\section{Algorithm}
Since we have constructed operator $C$, that meets our requirements, we can reformulate Algorithm \ref{alg:Krylov base} to implementable form.
\begin{algorithm}[H]
\caption{Krylov eigenvalue solver with filtered time-domain}\label{alg:Krylov pro}
   \begin{algorithmic}
        \State \textbf{Input: } weight function $\alpha$, start vector $r$ with $\|r\|_2 = 1$, $M^{-1}$, $S$, dimension $m$ of the Krylov space, time-step $\tau$, number of time-steps $L$
        \State $b_0 \gets r$
        \For{$k = 1, \dots, m-1$}\Comment{Krylov loop}
            \State $y_{-1}, y_{0} \gets r$
            \State $b_k \gets \tau \alpha(0) r$
            \For{$l = 1, \dots L-1$}\Comment{Time-stepping in each Krylov step}
                \State $y_l \gets -\tau^2 M^{-1}S y_{l-1} + 2y_{l-1} - y_{l-2}$ \Comment{$y_l$ represents $y_l(r)$ from \eqref{eq:fd for wave eq}}
                \State $b_k \gets b_k + \tau \alpha(\tau l)y_l$ \Comment{Computation of \eqref{eq:C operator}}
            \EndFor
            \State $b_k \gets b_k - \sum_{i=0}^{k-1}(b_i^Tb_k)b_i$ \Comment{Gram-Schmidt orthogonalization}
            \If{$\|b_k\|_2 \neq 0$}
                \State $b_k\gets b_k/\|b_k\|_2$ \Comment{normalization}
            \Else
                \State $m\gets k$   \Comment{$b_k$ is not linear independent from $b_0, \dots, b_{k-1}$. Exact eigenspace}
                \State \textbf{break} \Comment{ is a subspace of $\mathcal{K}_k(C; r)$.}
            \EndIf
        \EndFor
        \State $B_m \gets (b_0, \dots, b_{m-1})$ \Comment{Projection matrix}
        \State $A \gets B_m^T M^{-1}S B_m$
        \State solve $Av_m = \omega_m^2 v_m$ with power iteration
    \end{algorithmic} 
\end{algorithm}
Chosen time-step $\tau$ should fulfill CFL condition (see Lemma \ref{lemma:cfl}) for the largest absolute value among eigenvalues $\omega^2$ of \eqref{eq:matrix form}. Computational complexity of this method depends on the number of time-steps $L$ (and thus by the end time of integration $T = L\tau$) and the dimension of Krylov space $m$. Notice, that in presented algorithm we can easily increase the dimension of Krylov space without large computational costs, since increasing $m$ by $\hat{m}$ requires only $\hat{m}$ additional iterations of Krylov loop and solving eigenvalue problem with power iteration. For more details about the stopping criterion we refer to \cite[p. 8--9]{nannen}. In the next chapter we will discuss the choice of the weight function $\alpha$.



\chapter{Choice of the weight function}
\label{chapter:function}
\cite{nannen}\cite{numodes}

\bibliographystyle{alpha} 
%\bibliographystyle{abbrv}
\bibliography{literature.bib}

\end{document}
